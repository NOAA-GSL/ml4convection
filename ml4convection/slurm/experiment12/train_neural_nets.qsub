#!/bin/tcsh

#SBATCH --job-name="train_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --nodes=1
#SBATCH --ntasks=8           # 8 tasks per node
#SBATCH --cpus-per-task=2
#SBATCH --ntasks-per-node=8  # 8 GPUs per node
#SBATCH --exclusive
#SBATCH --time=30:00:00
#SBATCH --array=9-10,19-20,29-30,39-40,49-50,59-60,69-70,79-80,89-90
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=train_neural_nets_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_standalone/ml4convection"
set TEMPLATE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_models/experiment12/templates"
set TOP_OUTPUT_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_models/experiment12"

set TRAINING_PREDICTOR_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_project/predictors/quality_controlled/partial_grids"
set VALIDN_PREDICTOR_DIR_NAME="${TRAINING_PREDICTOR_DIR_NAME}"
set TRAINING_TARGET_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_project/targets/new_echo_classification/no_tracking/partial_grids"
set VALIDN_TARGET_DIR_NAME="${TRAINING_TARGET_DIR_NAME}"

set BATCH_SIZES=(64 64 80 80 96 96 112 112 128 128 64 64 80 80 96 96 112 112 128 128 64 64 80 80 96 96 112 112 128 128 64 64 80 80 96 96 112 112 128 128 64 64 80 80 96 96 112 112 128 128 64 64 80 80 96 96 112 112 128 128 64 64 80 80 96 96 112 112 128 128 64 64 80 80 96 96 112 112 128 128 64 64 80 80 96 96 112 112 128 128)
set L2_WEIGHTS=(0.0000001000 0.0000001000 0.0000001000 0.0000001000 0.0000001000 0.0000001000 0.0000001000 0.0000001000 0.0000001000 0.0000001000 0.0000003162 0.0000003162 0.0000003162 0.0000003162 0.0000003162 0.0000003162 0.0000003162 0.0000003162 0.0000003162 0.0000003162 0.0000010000 0.0000010000 0.0000010000 0.0000010000 0.0000010000 0.0000010000 0.0000010000 0.0000010000 0.0000010000 0.0000010000 0.0000031623 0.0000031623 0.0000031623 0.0000031623 0.0000031623 0.0000031623 0.0000031623 0.0000031623 0.0000031623 0.0000031623 0.0000100000 0.0000100000 0.0000100000 0.0000100000 0.0000100000 0.0000100000 0.0000100000 0.0000100000 0.0000100000 0.0000100000 0.0000316228 0.0000316228 0.0000316228 0.0000316228 0.0000316228 0.0000316228 0.0000316228 0.0000316228 0.0000316228 0.0000316228 0.0001000000 0.0001000000 0.0001000000 0.0001000000 0.0001000000 0.0001000000 0.0001000000 0.0001000000 0.0001000000 0.0001000000 0.0003162278 0.0003162278 0.0003162278 0.0003162278 0.0003162278 0.0003162278 0.0003162278 0.0003162278 0.0003162278 0.0003162278 0.0010000000 0.0010000000 0.0010000000 0.0010000000 0.0010000000 0.0010000000 0.0010000000 0.0010000000 0.0010000000 0.0010000000)
set LAG_TIME_COUNTS=(2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3 2 3)
set LAG_TIME_COMBO_STRINGS=("0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200" "0 600" "0 600 1200")

set batch_size=${BATCH_SIZES[$SLURM_ARRAY_TASK_ID]}
set l2_weight=${L2_WEIGHTS[$SLURM_ARRAY_TASK_ID]}
set lag_time_count=${LAG_TIME_COUNTS[$SLURM_ARRAY_TASK_ID]}

set batch_size_string=`printf "%02d" $batch_size`
set l2_weight_string=`printf "%.10f" $l2_weight`
set lag_time_count_string=`printf "%d" $lag_time_count`

set template_file_name="${TEMPLATE_DIR_NAME}/model_l2-weight=${l2_weight_string}_num-lag-times=${lag_time_count_string}.h5"
set output_dir_name="${TOP_OUTPUT_DIR_NAME}/batch-size=${batch_size_string}_l2-weight=${l2_weight_string}_num-lag-times=${lag_time_count_string}"
echo $output_dir_name

python3 -u "${CODE_DIR_NAME}/train_neural_net.py" \
--training_predictor_dir_name="${TRAINING_PREDICTOR_DIR_NAME}" \
--validn_predictor_dir_name="${VALIDN_PREDICTOR_DIR_NAME}" \
--training_target_dir_name="${TRAINING_TARGET_DIR_NAME}" \
--validn_target_dir_name="${VALIDN_TARGET_DIR_NAME}" \
--input_model_file_name="${template_file_name}" \
--output_model_dir_name="${output_dir_name}" \
--lead_time_seconds=0 \
--lag_times_seconds ${LAG_TIME_COMBO_STRINGS[$SLURM_ARRAY_TASK_ID]} \
--include_time_dimension=1 \
--normalize=1 \
--uniformize=1 \
--num_examples_per_batch=${batch_size} \
--max_examples_per_day_in_batch=8 \
--use_partial_grids=1 \
--num_epochs=1000 \
--num_training_batches_per_epoch=64 \
--num_validn_batches_per_epoch=32
